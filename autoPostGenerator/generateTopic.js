async function getNextTopic(e){const n=`\n\ub2f9\uc2e0\uc740 \ud504\ub860\ud2b8\uc5d4\ub4dc \uacf5\ubd80 \uacc4\ud68d\uc744 \uc138\uc6b0\ub294 AI\uc785\ub2c8\ub2e4.\n\uc544\ub798\ub294 \uc9c0\uae08\uae4c\uc9c0 \uc0ac\uc6a9\uc790\uac00 \uacf5\ubd80\ud55c \uc8fc\uc81c\uc785\ub2c8\ub2e4:\n\n${e.map(((e,n)=>`${n+1}. ${e}`)).join("\n")}\n\n\uc774\uc5b4\uc11c \ud559\uc2b5\ud558\uba74 \uc88b\uc740 \uc8fc\uc81c\ub97c 1\uac1c\ub9cc, \uac04\uacb0\ud558\uac8c \ucd94\ucc9c\ud574\uc8fc\uc138\uc694.\n`;return(await openai.chat.completions.create({model:"gpt-4",messages:[{role:"user",content:n}]})).choices[0].message.content.trim().replace(/^[-\u2022\d.]\s*/,"")}async function appendTopic(){const e=Object.values(topics),n=await getNextTopic(e),t=(new Date).toISOString().slice(0,10);nextTopics[t]=n,fs.writeFileSync(nextTopicsFilePath,JSON.stringify(nextTopics,null,2),"utf8")}require("dotenv").config();const fs=require("fs"),path=require("path"),OpenAI=require("openai"),topicsFilePath=path.join(__dirname,"topics.json"),nextTopicsFilePath=path.join(__dirname,"nextTopics.json"),topics=fs.existsSync(topicsFilePath)?JSON.parse(fs.readFileSync(topicsFilePath,"utf8")):{},nextTopics=fs.existsSync(nextTopicsFilePath)?JSON.parse(fs.readFileSync(nextTopicsFilePath,"utf8")):{},openai=new OpenAI({apiKey:process.env.OPENAI_API_KEY});appendTopic();